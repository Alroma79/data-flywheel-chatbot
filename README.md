# Data Flywheel Chatbot ğŸ¤–

A dynamic, configurable chatbot API built with FastAPI that supports multiple AI models, database persistence, and real-time configuration updates.

## ğŸš€ Features

- **Dynamic AI Model Configuration**: Switch between different OpenAI models and adjust parameters on-the-fly
- **Database Persistence**: Store chat history, user feedback, and configurations in PostgreSQL or SQLite
- **RESTful API**: Clean, well-documented API endpoints with automatic OpenAPI documentation
- **Error Handling & Logging**: Comprehensive error handling with structured logging
- **Input Validation**: Robust input sanitization and validation using Pydantic
- **CORS Support**: Configurable CORS settings for frontend integration
- **Docker Support**: Containerized deployment with Docker Compose

## ğŸ—ï¸ Architecture

```
data-flywheel-chatbot/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ main.py          # FastAPI application setup
â”‚       â”œâ”€â”€ routes.py        # API endpoints
â”‚       â”œâ”€â”€ models.py        # SQLAlchemy ORM models
â”‚       â”œâ”€â”€ schemas.py       # Pydantic validation schemas
â”‚       â”œâ”€â”€ db.py           # Database configuration
â”‚       â”œâ”€â”€ config.py       # Application configuration
â”‚       â”œâ”€â”€ utils.py        # Utility functions
â”‚       â”œâ”€â”€ init_db.py      # Database initialization
â”‚       â””â”€â”€ requirements.txt
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ backend.Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ frontend/               # Frontend application (if applicable)
â”œâ”€â”€ .env                   # Environment variables
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ› ï¸ Installation & Setup

### Prerequisites

- Python 3.8+
- PostgreSQL (optional, SQLite is used by default)
- OpenAI API Key

### Local Development Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/Alroma79/data-flywheel-chatbot.git
   cd data-flywheel-chatbot
   ```

2. **Set up Python virtual environment**
   ```bash
   cd backend
   python -m venv venv
   
   # On Windows
   venv\Scripts\activate
   
   # On macOS/Linux
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   cd app
   pip install -r requirements.txt
   ```

4. **Configure environment variables**
   
   Create a `.env` file in the project root:
   ```env
   # Required
   OPENAI_API_KEY=your_openai_api_key_here
   
   # Optional (defaults provided)
   DATABASE_URL=sqlite:///./chatbot.db
   DEBUG=false
   CORS_ORIGINS=*
   DEFAULT_MODEL=gpt-4o
   DEFAULT_TEMPERATURE=0.7
   LOG_LEVEL=INFO
   ```

5. **Initialize the database**
   ```bash
   python -c "from init_db import init_database; init_database()"
   ```

6. **Run the application**
   ```bash
   uvicorn main:app --reload --host 0.0.0.0 --port 8000
   ```

The API will be available at `http://localhost:8000`

### Docker Deployment

1. **Using Docker Compose**
   ```bash
   docker-compose -f docker/docker-compose.yml up -d
   ```

## ğŸ“š API Documentation

Once the application is running, visit:
- **Interactive API Docs**: `http://localhost:8000/docs`
- **ReDoc Documentation**: `http://localhost:8000/redoc`

### Key Endpoints

#### Chat
- `POST /api/v1/chat` - Send a message to the chatbot
- `GET /api/v1/chat-history` - Retrieve chat history

#### Configuration
- `GET /api/v1/config` - Get current chatbot configuration
- `POST /api/v1/config` - Update chatbot configuration

#### Feedback
- `POST /api/v1/feedback` - Submit user feedback
- `GET /api/v1/feedback` - Retrieve feedback entries

#### Health
- `GET /` - API status and version
- `GET /health` - Health check endpoint

### Example Usage

**Send a chat message:**
```bash
curl -X POST "http://localhost:8000/api/v1/chat" \
     -H "Content-Type: application/json" \
     -d '{"message": "Hello, how can you help me?"}'
```

**Update chatbot configuration:**
```bash
curl -X POST "http://localhost:8000/api/v1/config" \
     -H "Content-Type: application/json" \
     -d '{
       "name": "custom_config",
       "config_json": {
         "system_prompt": "You are a helpful assistant specialized in data analysis.",
         "model": "gpt-4o",
         "temperature": 0.5,
         "max_tokens": 1000
       }
     }'
```

## ğŸ”§ Configuration

The application supports various configuration options through environment variables:

| Variable | Description | Default |
|----------|-------------|---------|
| `OPENAI_API_KEY` | OpenAI API key (required) | - |
| `DATABASE_URL` | Database connection string | `sqlite:///./chatbot.db` |
| `DEBUG` | Enable debug mode | `false` |
| `CORS_ORIGINS` | Allowed CORS origins | `*` |
| `DEFAULT_MODEL` | Default OpenAI model | `gpt-4o` |
| `DEFAULT_TEMPERATURE` | Default temperature setting | `0.7` |
| `LOG_LEVEL` | Logging level | `INFO` |

## ğŸ§ª Testing

Run tests using pytest:
```bash
pytest tests/
```

## ğŸ“ Development

### Code Style
- Follow PEP 8 guidelines
- Use type hints where applicable
- Add docstrings to all functions and classes
- Maintain test coverage above 80%

### Contributing
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

## ğŸš€ Deployment

### Production Considerations
- Use PostgreSQL for production databases
- Set up proper logging and monitoring
- Configure rate limiting
- Use environment-specific configuration files
- Set up SSL/TLS certificates
- Implement proper backup strategies

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ¤ Support

For support and questions:
- Create an issue on GitHub
- Contact: alroma79@gmail.com

## ğŸ”„ Changelog

### v1.0.0
- Initial release with dynamic configuration support
- Database persistence for chat history and feedback
- Comprehensive error handling and logging
- Docker support for easy deployment
